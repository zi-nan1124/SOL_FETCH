import os
import csv
import pandas as pd
import config
import datetime
from tqdm import tqdm  # âœ… è¿›åº¦æ¡åº“
from SolanaSlotFinder import SolanaSlotFinder
from RaydiumPoolFetcher import RaydiumPoolFetcher
from TransactionFetcher import TransactionFetcher
from LogDecoder import LogDecoder
import concurrent.futures
import threading
from solders.pubkey import Pubkey
import time
import logging
import httpx
from solana.exceptions import SolanaRpcException


CONFIG = config.CONFIG  # ç›´æ¥ä½¿ç”¨ CONFIG


class SolanaFetcher:
    """
    Solana äº¤æ˜“æ•°æ®æŠ“å–å™¨ï¼šæ”¯æŒä¸¤ç§åˆå§‹åŒ–æ–¹å¼ï¼š
    1. ä¼ å…¥ `start_datetime` å’Œ `end_datetime`ï¼Œè‡ªåŠ¨è®¡ç®— Slot
    2. ä¼ å…¥ `start_slot` å’Œ `end_slot`ï¼Œç›´æ¥ä½¿ç”¨æŒ‡å®š Slot
    """

    def __init__(self, start_slot, end_slot, rpc_url):
        """
        åˆå§‹åŒ– SolanaFetcherï¼ˆä½¿ç”¨ Slot ç›´æ¥åˆå§‹åŒ–ï¼‰
        :param start_slot: èµ·å§‹ Slot
        :param end_slot: ç»“æŸ Slot
        :param slot_finder: Slot è§£æå™¨
        :param log_decoder: äº¤æ˜“æ—¥å¿—è§£ç å™¨
        """
        self.start_slot = start_slot
        self.end_slot = end_slot
        self.rpc_url = rpc_url
        self.slot_finder = SolanaSlotFinder(rpc_url)
        self.TX_SIG_fetcher = TransactionFetcher.from_slots(self.rpc_url, self.slot_finder, self.start_slot, self.end_slot)

        # **ä» CONFIG è¯»å–å¤šä¸ª RPC URL**
        self.rpc_urls = [config.CONFIG[key] for key in config.CONFIG if key.startswith("rpc_url")]

        if not self.rpc_urls:
            raise ValueError("âŒ æ²¡æœ‰å¯ç”¨çš„ RPC ç«¯ç‚¹ï¼Œè¯·æ£€æŸ¥ CONFIG é…ç½®ï¼")

        # **åˆ›å»ºå¤šä¸ª LogDecoder å®ä¾‹**
        self.log_decoders = [LogDecoder(url) for url in self.rpc_urls]

        print(f"âœ… åˆå§‹åŒ– {len(self.log_decoders)} ä¸ª LogDecoder å®ä¾‹ï¼Œå‡è¡¡è´Ÿè½½ Solana èŠ‚ç‚¹")

        # å¸¸è§ç¨³å®šå¸ç¬¦å·
        self.stable_symbols = {"USDC", "USDT", "USDD"}

    @classmethod
    def from_datetime(cls, start_datetime, end_datetime,rpc_url):
        """
        ä½¿ç”¨æ—¶é—´æˆ³åˆå§‹åŒ– SolanaFetcherï¼ˆè‡ªåŠ¨è®¡ç®— Slotï¼‰
        :param start_datetime: èµ·å§‹æ—¶é—´ï¼ˆdatetime å¯¹è±¡ï¼‰
        :param end_datetime: ç»“æŸæ—¶é—´ï¼ˆdatetime å¯¹è±¡ï¼‰
        :param slot_finder: Slot è§£æå™¨
        :param log_decoder: äº¤æ˜“æ—¥å¿—è§£ç å™¨
        :return: SolanaFetcher å®ä¾‹
        """
        start_timestamp = int(start_datetime.timestamp())
        end_timestamp = int(end_datetime.timestamp())
        slot_finder = SolanaSlotFinder(rpc_url)
        start_slot = slot_finder.find_closest_slot(start_timestamp)
        end_slot = slot_finder.find_closest_slot(end_timestamp)

        return cls(start_slot, end_slot, rpc_url)


    def read_input(self):
        """
        è¯»å– `input.csv` è¿”å›æ‰€æœ‰ `mint1, mint2` å¯¹
        """
        input_file = os.path.join(CONFIG["input_path"], "input.csv")
        if not os.path.exists(input_file):
            print(f"âŒ è¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ°: {input_file}")
            return []

        print(f"ğŸ” è¯»å–è¾“å…¥æ–‡ä»¶: {input_file}")
        with open(input_file, mode="r", newline="") as file:
            reader = csv.reader(file)
            next(reader, None)  # è·³è¿‡ CSV å¤´éƒ¨
            return [row for row in reader]  # è¿”å› mint1, mint2 äº¤æ˜“å¯¹

    @staticmethod
    def print_stage_header(message):
        """
        æ‰“å°é˜¶æ®µæ€§è¾“å‡º
        """
        border = "=" * 50
        print(f"\n{border}\n <<<<<<<<<< {message}  >>>>>>>>>> \n{border}\n")

    def fetch_pool_by_token(self, mint1, mint2):
        """
        è·å– Raydium æµåŠ¨æ€§æ± æ•°æ®
        """
        print(f"ğŸ“¡ è·å– {mint1} / {mint2} çš„æµåŠ¨æ€§æ± æ•°æ®...")
        fetcher = RaydiumPoolFetcher(mint1, mint2)
        fetcher.run()
        return fetcher.mint1symbol, fetcher.mint2symbol

    def read_pool_file(self, symbol1, symbol2):
        """
        è¯»å– `POOL_symbol1_symbol2.csv` å¹¶è¿”å› `pool_id` åˆ—æ•°æ®
        """
        pool_file = os.path.join(CONFIG["output_path"], "POOL", f"POOL_{symbol1}_{symbol2}.csv")

        if not os.path.exists(pool_file):
            print(f"âŒ Pool æ–‡ä»¶æœªæ‰¾åˆ°: {pool_file}")
            return []

        print(f"ğŸ” è¯»å–æµåŠ¨æ€§æ± æ–‡ä»¶: {pool_file}")
        pool_ids = []
        with open(pool_file, mode="r", newline="") as file:
            reader = csv.DictReader(file)
            for row in reader:
                if "pool_id" in row:
                    pool_ids.append(row["pool_id"])
        return pool_ids

    def fetch_transactions_for_pool(self, symbol1, symbol2):
        """
        è¯»å– `POOL_symbol1_symbol2.csv` è·å– `pool_id` å¹¶ä½¿ç”¨å¤šçº¿ç¨‹æŸ¥è¯¢äº¤æ˜“
        """
        file_name = f"{symbol1}_{symbol2}.csv"

        # è¯»å– `POOL_symbol1_symbol2.csv` è·å– `pool_id`
        market_address_list = self.read_pool_file(symbol1, symbol2)

        # çº¿ç¨‹æ•°è®¾ä¸º `15`
        max_threads = 15

        def fetch_for_market(market_address):
            """å•ç‹¬å¤„ç†ä¸€ä¸ªå¸‚åœºåœ°å€çš„äº¤æ˜“è·å–"""
            attempt = 0
            max_retries = 5  # æœ€å¤§é‡è¯•æ¬¡æ•°

            while attempt < max_retries:
                try:
                    logging.info(
                        f"Fetching transactions for Market Address: {market_address} (Attempt {attempt + 1}/{max_retries})")

                    # å‘é€è¯·æ±‚
                    self.TX_SIG_fetcher.fetch_transactions(market_address,file_name)

                    # æˆåŠŸè·å–æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    break

                except (httpx.ReadTimeout, SolanaRpcException) as e:
                    logging.warning(f"Request failed: {e}. Retrying... (Attempt {attempt + 1})")

                    # è®¡ç®—æŒ‡æ•°é€€é¿æ—¶é—´ï¼š2^attempt ç§’ï¼ˆæœ€å¤§ 32 ç§’ï¼‰
                    wait_time = min(2 ** attempt, 32)
                    time.sleep(wait_time)

                    attempt += 1

            if attempt == max_retries:
                logging.error(
                    f"Failed to fetch transactions for {market_address} after {max_retries} attempts. Skipping...")

        # **ä½¿ç”¨ `ThreadPoolExecutor` è¿›è¡Œå¤šçº¿ç¨‹æŸ¥è¯¢**
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
            executor.map(fetch_for_market, market_address_list)

    def read_signatures_file(self, symbol1, symbol2):
        """
        è¯»å– `SIGNATURE_symbol1_symbol2.csv` å¹¶è¿”å›ç¬¦åˆ slot è¿‡æ»¤æ¡ä»¶çš„äº¤æ˜“ç­¾å
        """
        sig_file = os.path.join(CONFIG["output_path"], "SIGNATURE", f"{symbol1}_{symbol2}.csv")
        data_file1 = os.path.join(CONFIG["output_path"], "DATA", f"{symbol1}_{symbol2}.csv")
        data_file2 = os.path.join(CONFIG["output_path"], "DATA", f"{symbol2}_{symbol1}.csv")

        if not os.path.exists(sig_file):
            print(f"âŒ ç­¾åæ–‡ä»¶æœªæ‰¾åˆ°: {sig_file}")
            return []

        print(f"ğŸ” è¯»å–äº¤æ˜“ç­¾åæ–‡ä»¶: {sig_file}")

        # è¯»å– datafile1 å’Œ datafile2ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©º DataFrame
        def load_data_file(file_path):
            return pd.read_csv(file_path, usecols=["Signature"]) if os.path.exists(file_path) else pd.DataFrame(
                columns=["Signature"])

        df_data1 = load_data_file(data_file1)
        df_data2 = load_data_file(data_file2)

        # åˆå¹¶ data_file1 å’Œ data_file2 çš„ Signature
        existing_signatures = set(df_data1["Signature"]).union(set(df_data2["Signature"]))

        # è¯»å– sig_file å¹¶è¿›è¡Œè¿‡æ»¤
        filtered_signatures = []
        with open(sig_file, mode="r", newline="") as file:
            reader = csv.DictReader(file)
            for row in reader:
                if row["Slot"] is None:
                    continue
                slot = int(row["Slot"])
                signature = row["Signature"]

                # è¿‡æ»¤ slot èŒƒå›´ï¼Œå¹¶ä¸” Signature ä¸èƒ½åœ¨ datafile ä¸­å·²å­˜åœ¨
                if self.start_slot <= slot <= self.end_slot and signature not in existing_signatures:
                    filtered_signatures.append((signature, row["Market_Address"]))

        return filtered_signatures

    def process_signatures_in_batches(self, tx_signatures):
        """
        å¤šçº¿ç¨‹å¤„ç†äº¤æ˜“ç­¾åï¼Œå¹¶åˆ†é…åˆ°ä¸åŒçš„ LogDecoderï¼ˆSolana RPC ç«¯ç‚¹ï¼‰
        """
        if not tx_signatures:
            print("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„äº¤æ˜“ç­¾åï¼Œè·³è¿‡è§£ç ï¼")
            return

        N = len(self.log_decoders) * 100  # æœ€å¤§çº¿ç¨‹æ•°
        total_tasks = len(tx_signatures)

        # **1ï¸âƒ£ åˆ›å»ºå…¨å±€è¿›åº¦æ¡**
        global_progress = tqdm(total=total_tasks, desc="Overall Progress", position=0, leave=True, dynamic_ncols=True,
                               unit="tx")

        # **2ï¸âƒ£ è®¡ç®—æ‰¹æ¬¡æ•°é‡**
        batch_size = max(1, total_tasks // N)
        batches = [tx_signatures[i:i + batch_size] for i in range(0, total_tasks, batch_size)]

        lock = threading.Lock()  # **çº¿ç¨‹å®‰å…¨é”**

        # **3ï¸âƒ£ çº¿ç¨‹æ± æ‰§è¡Œ**
        with concurrent.futures.ThreadPoolExecutor(max_workers=N) as executor:
            futures = []

            def process_batch(batch, thread_id, log_decoder):
                """ å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„äº¤æ˜“ç­¾åï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„ log_decoder """
                start_time = time.time()
                print(f"\nâœ… å·²å»ºç«‹ {thread_id} å·çº¿ç¨‹ï¼Œä½¿ç”¨ RPC {log_decoder.solana_client._provider.endpoint_uri}")

                for transaction_signature, market_address in batch:
                    log_decoder.decode(transaction_signature, market_address)
                    with lock:
                        global_progress.update(1)

                elapsed_time = time.time() - start_time
                print(f"\nâœ… çº¿ç¨‹ {thread_id} å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(batch)} ç¬”äº¤æ˜“ï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’")

            # **4ï¸âƒ£ æäº¤ä»»åŠ¡**
            for idx, batch in enumerate(batches):
                log_decoder = self.log_decoders[idx % len(self.log_decoders)]  # è½®è¯¢é€‰æ‹©ä¸åŒçš„ RPC èŠ‚ç‚¹
                futures.append(executor.submit(process_batch, batch, idx, log_decoder))

            # **5ï¸âƒ£ ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ**
            concurrent.futures.wait(futures)
            global_progress.close()

    def run(self):
        """
        è¿è¡Œ SolanaFetcherï¼Œå¤„ç†æ‰€æœ‰ `mint1, mint2` äº¤æ˜“å¯¹
        """
        self.print_stage_header("SOL_FETCHER STARTING")

        # è·å–æ‰€æœ‰äº¤æ˜“å¯¹
        token_pairs = self.read_input()

        for mint1, mint2 in token_pairs:
            self.print_stage_header("FETCHING POOL")
            symbol1, symbol2 = self.fetch_pool_by_token(mint1, mint2)

            # è¯†åˆ«éç¨³å®šå¸
            unstable_symbol = symbol1 if symbol2 in self.stable_symbols else symbol2
            self.print_stage_header(f"SUCCESS FETCH POOL BY {symbol1} {symbol2}")

            # è·å–äº¤æ˜“ç­¾å
            self.print_stage_header("FETCHING TX")
            self.fetch_transactions_for_pool(symbol1, symbol2)
            self.print_stage_header("FETCH TX SUCCESS")

            #
            self.print_stage_header("DECODING TX LOGS")
            tx_signatures = self.read_signatures_file(symbol1, symbol2)
            self.process_signatures_in_batches(tx_signatures)
            self.print_stage_header("DECODING TX SUCCESS")

# ========== ä¸»å‡½æ•° ========== #
if __name__ == "__main__":
    start_datetime = datetime.datetime(2025, 2, 27, 0, 0)
    end_datetime = datetime.datetime(2025, 2, 27, 1, 0)
    start_slot = 323278200
    end_slot = 323279200
    rpc_url = "https://wild-boldest-rain.solana-mainnet.quiknode.pro/b95f33839916945a42159c53ceab4d7468a51a69/"

    fetcher = SolanaFetcher(start_slot,end_slot,rpc_url)
    #fetcher = SolanaFetcher.from_datetime(start_datetime, end_datetime,rpc_url)
    fetcher.run()

